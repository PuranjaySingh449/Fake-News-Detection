# Fake News Detection Pipeline

**BERT 81.2%** vs baselines on PolitiFact + GossipCop (balanced datasets).[1]

## üìä Results

| Model             | Accuracy | F1-Score |
|-------------------|----------|----------|
| **BERT**          | **81.2%**| **80.9%**|
| Logistic Regression| 79.2%   | 78.7%   |
| Naive Bayes       | 78.2%   | 78.0%   |
| BiLSTM            | 77.2%   | 77.4%   |[1]

## üöÄ Quick Start

```bash
pip install -r requirements.txt
python train_complete_pipeline.py  # ~30min on RTX GPU
```

## üóÇÔ∏è Datasets

Place CSVs in `D:\fakeNewsPoli\` (or update paths):

```
D:\fakeNewsPoli\
‚îú‚îÄ‚îÄ politifact_real.csv
‚îú‚îÄ‚îÄ politifact_fake.csv
‚îú‚îÄ‚îÄ gossipcop_real.csv
‚îî‚îÄ‚îÄ gossipcop_fake.csv
```

**Column**: `title` (text data)

## üìÅ Outputs

```
‚úÖ logistic_regression_model.pkl (79.2%)
‚úÖ naive_bayes_model.pkl (78.2%) 
‚úÖ bilstm_model_cross_domain.pt (77.2%)
‚úÖ bert_model_cross_domain.pt (81.2% - BEST)
‚úÖ tfidf_vectorizer.pkl
‚úÖ bilstm_vocab.pkl
‚úÖ training_results_comparison.csv
```

## ‚öôÔ∏è Requirements

```txt
torch>=2.0.0
transformers>=4.30.0
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0
```

## ‚ú® Features

- **4 Models**: BERT, BiLSTM, Logistic, Naive Bayes
- **GPU Ready**: Auto CUDA + mixed precision (FP16)
- **Cross-Domain**: PolitiFact + GossipCop
- **Balanced**: Auto real/fake balancing
- **Production**: All models + artifacts saved

## üîß GPU Tips

- **OOM?** `BATCH_SIZE=16` or `MAX_LENGTH=128`
- **CPU slow?** Install CUDA PyTorch
- **Paths wrong?** Edit top of script

***

**‚≠ê & üöÄ if BERT beats your baselines!**[1]
